# -*-coding: "utf-8"-*-

"""
# File:        data_process.py
# Author:      "liyi"
# CreateTime:  2022/6/20 15:12
# Version:     python 3.6
# Description: Â∞ÜÁî®‰æã‰∏≠ÁöÑÊâÄÊúâËæìÂÖ•‰ø°Âè∑ÊèêÂèñÂá∫Êù•ÔºåÁªÑÊàêËæìÂÖ•Áü©ÈòµÔºõ
#              Â∞ÜÈ¢ÑÊúüÁªìÊûúÊèêÂèñÂá∫Êù•ÔºåÁªÑÊàêÈ¢ÑÊúüÁªìÊûúÁü©ÈòµÔºõ
"""
import copy
from collections import deque

import openpyxl
from copy import deepcopy
# from time import strftime
import re
import time


def is_contain_chinese(check_obj: str) -> bool:
    """
    Âà§Êñ≠Â≠óÁ¨¶‰∏≤‰∏≠ÊòØÂê¶ÂåÖÂê´‰∏≠Êñá
    :return: Y True, N False
    """
    for ch in check_obj:
        if u'\u4e00' <= ch <= u'\u9fff':
            return True
    return False

location_preprocess = 4
location_steps = 5
location_expect_result = 6
location_actual_result = 7

class DataProcess(object):
    def __init__(self, filepath):

        self.filepath = filepath

        # ÂàùÂßãÂåñÂåÖÂê´ÊâÄÊúâËæìÂÖ•‰ø°Âè∑ÁöÑÁü©Èòµ
        self.InMatrix = deque()

        # ÂàùÂßãÂåñÂåÖÂê´ÊâÄÊúâËæìÂá∫‰ø°Âè∑ÁöÑÁü©Èòµ
        self.ExpMatrix = deque()

        # ÂàùÂßãÂåñÂçï‰æãËæìÂÖ•‰ø°Âè∑
        self.InSingle = deque()

        # ÂàùÂßãÂåñÂçï‰æãËæìÂá∫‰ø°Âè∑
        self.ExpSingle = deque()

        # ÂàùÂßãÂåñÂõûÂΩíÁî®‰æãËæìÂÖ•‰ø°Âè∑Áü©Èòµ
        self.InMatrix_Rec = deque()

        # ÂàùÂßãÂåñÂõûÂΩíÁî®ÂäõËæìÂá∫‰ø°Âè∑Áü©Èòµ
        self.ExpMatrix_Rec = deque()

    def loadExcel(self):
        # Ê†πÊçÆÊñá‰ª∂Âú∞ÂùÄËé∑ÂèñÊñáÊ°£ workbook
        wb = openpyxl.load_workbook(self.filepath)
        # Ëé∑ÂèñsheetË°®Ê†ºÂêçÁß∞Êï∞ÁªÑ
        sheet_names = wb.sheetnames
        # Ê†πÊçÆsheetÂêçÁß∞Ëé∑ÂèñsheetÊï∞ÊçÆ
        sheet_data = {}
        case_num = {}
        for item in sheet_names:
            sheet_data[item] = wb.get_sheet_by_name(item)
            # Ëé∑ÂèñÁî®‰æã‰∏™Êï∞
            case_num[item] = sheet_data[item].max_row - 2
        # print(sheet_data, case_num)
        # {'test1': <Worksheet "test1">, 'test2': <Worksheet "test1">}
        # {'test1': 2, 'test2': 2}
        # print(case_num)
        return sheet_data, case_num

    def _extractIn(self) -> deque:
        """
        ÊèêÂèñË°®Ê†º‰∏≠ÊâÄÊúâÁöÑËæìÂÖ•‰ø°Âè∑ÔºåÂÜôÂÖ•ËæìÂÖ•Áü©Èòµ
        :return: ËæìÂÖ•‰ø°Âè∑Áü©Èòµ InMatrix
        """
        # ÂàùÂßãÂåñ‰∏Ä‰∏™Â≠óÂÖ∏
        dict = {"pre_process": [], "steps": []}
        # dict['pre_process'] = []
        # dict['steps'] = []

        # Ëé∑ÂèñË°®Ê†ºÊï∞ÊçÆÂíåÁî®‰æã‰∏™Êï∞
        sheet_data, case_num = self.loadExcel()

        # Â∞ÜÂâçÁΩÆÊù°‰ª∂ÂíåÊìç‰ΩúÊ≠•È™§‰∏≠ÁöÑÂÜÖÂÆπÔºå‰æùÊçÆÊç¢Ë°åÁ¨¶ÂàÜÂâ≤Âá∫Êù•ÔºåËé∑Âæó‰ø°Âè∑ÁöÑËµãÂÄºÂä®‰Ωú
        keys = list(sheet_data.keys())
        # sheet‰∏™Êï∞
        len_ = len(keys)
        """
        self.InMatrix    |----------------------------------------------------------------------------------------------
        nrows = 1        |[{"pre_process":[Êìç‰Ωú1ÔºåÊìç‰Ωú2...], "steps":[Ê≠•È™§1ÔºåÊ≠•È™§2...]}, ... , ÊúÄÂêé‰∏Ä‰∏™caseÁöÑÊìç‰ΩúÂ≠óÂÖ∏}
        ncols = sum_case |                                                                                  
                         |----------------------------------------------------------------------------------------------
        """
        for i in range(1, len_):
            for j in range(3, case_num[keys[i]] + 3):
                # Ëé∑ÂèñÂâçÁΩÆÊù°‰ª∂ÁöÑ‰ø°Âè∑ËÆæÁΩÆ
                cell_pre = sheet_data[keys[i]].cell(j, location_preprocess).value
                if cell_pre: # Âà§Êñ≠ÂâçÁΩÆÊù°‰ª∂‰∏ç‰∏∫Á©∫
                    dict["pre_process"] = cell_pre.split("\n")
                    for item in dict["pre_process"]:
                        if is_contain_chinese(item): # ÂéªÊéâÂåÖÂê´Ê±âÂ≠óÁöÑËØ≠Âè•
                            dict["pre_process"].remove(item)
                else: # Ëã•‰∏∫Á©∫ÔºåËµãÁ©∫Êï∞ÁªÑ
                    dict["pre_process"] = []

                cell_step = sheet_data[keys[i]].cell(j, location_steps).value
                if cell_step:
                    dict["steps"] = cell_step.split("\n")
                    for item in dict["steps"]:
                        if is_contain_chinese(item):
                            dict["steps"].remove(item)
                else:
                    dict["steps"] = []
                self.InMatrix.append(deepcopy(dict))
                dict = {}
        # print(self.InMatrix)
        # ËæìÂá∫ÁöÑÁªìÊûúÊ†ºÂºèÂ¶Ç‰∏ãÔºö
        # deque([{'pre_process': ['MasterCylinderPressure=1', 'MasterCylinderQualifier=2'],
        #         'steps': ['SigGroup_27_ChkSm=3']},
        #        {'pre_process': ['MasterCylinderPressure=1', 'MasterCylinderQualifier=2'],
        #         'steps': ['SigGroup_27_ChkSm=3']},
        #        {'pre_process': ['MasterCylinderPressure=1', 'MasterCylinderQualifier=2'],
        #         'steps': ['SigGroup_27_ChkSm=3']},
        #        {'pre_process': ['MasterCylinderPressure=1', 'MasterCylinderQualifier=2'],
        #         'steps': ['SigGroup_27_ChkSm=3']}])
        return self.InMatrix

    def _extractIn_single(self, sheet_name: str, case_order: int) -> dict:
        """
        ‰ª• sheet ‰∏∫Áª¥Â∫¶ÊèêÂèñÁî®‰æãËæìÂÖ•
        :return:
        """
        # ÂÆö‰πâ‰∏Ä‰∏™Á©∫Â≠óÂÖ∏
        dict = {}

        # Ê†πÊçÆ sheet_name Ëé∑ÂèñÂÖ∂‰∏≠Áî®‰æãËæìÂÖ•
        sheet_data, case_num = self.loadExcel()
        for k, v in sheet_data:
            if sheet_name == k:
                try:
                    cell_pre = sheet_data[k].cell(case_order + 2, location_preprocess).value
                    dict["pre_process"] = cell_pre.split('\n')
                    cell_steps = sheet_data[k].cell(case_order + 2, location_steps).value
                    dict["steps"] = cell_steps.split('\n')
                except IndexError as e:
                    print("error", "Áî®‰æãÁºñÂè∑Ë∂ÖÂá∫Á¥¢ÂºïËåÉÂõ¥ÔºåËØ∑Ê£ÄÊü•ÁºñÂè∑ÊòØÂê¶Ê≠£Á°Æ")
        return dict

    def _extractExp(self):
        """
        ÊèêÂèñÁî®‰æã‰∏≠ÁöÑÈ¢ÑÊúüÁªìÊûú
        :return: È¢ÑÊúüÁªìÊûúÁü©Èòµ
        """
        dict = {}
        dict['expect'] = []

        # Ëé∑ÂèñË°®Ê†ºÊï∞ÊçÆÂíåÁî®‰æã‰∏™Êï∞
        sheet_data, case_num = self.loadExcel()

        # Â∞ÜÂâçÁΩÆÊù°‰ª∂ÂíåÊìç‰ΩúÊ≠•È™§‰∏≠ÁöÑÂÜÖÂÆπÔºå‰æùÊçÆÊç¢Ë°åÁ¨¶ÂàÜÂâ≤Âá∫Êù•ÔºåËé∑Âæó‰ø°Âè∑ÁöÑËµãÂÄºÂä®‰Ωú
        keys = list(sheet_data.keys())
        # sheet‰∏™Êï∞
        len_ = len(keys)

        # Â∞ÜÈ¢ÑÊúüÁªìÊûú‰∏≠ÁöÑÂÜÖÂÆπÔºå‰æùÊçÆÊç¢Ë°åÁ¨¶ÂàÜÂâ≤Âá∫Êù•
        for i in range(1, len_):
            for j in range(3, case_num[keys[i]] + 3):
                cell_pre = sheet_data[keys[i]].cell(j, location_expect_result).value
                dict["expect"] = cell_pre.split("\n")
                self.ExpMatrix.append(deepcopy(dict))
                dict = {}
        # print(self.ExpMatrix)
        # deque([{'expect': ['MasterCylinderPressure=1', 'MasterCylinderPressure=2', 'SigGroup_27_ChkSm=3']},
        #        {'expect': ['MasterCylinderPressure=1', 'MasterCylinderPressure=2', 'SigGroup_27_ChkSm=3']},
        #        {'expect': ['MasterCylinderPressure=1', 'MasterCylinderPressure=2', 'SigGroup_27_ChkSm=3']},
        #        {'expect': ['MasterCylinderPressure=1', 'MasterCylinderPressure=2', 'SigGroup_27_ChkSm=3']}])
        return self.ExpMatrix

    def _extractExp_single(self, sheet_name: str, case_order: int) -> dict:
        """
        ÊèêÂèñÂçï‰∏™Áî®‰æãÁöÑÈ¢ÑÊúüÁªìÊûú
        :return:
        """
        dict = {}
        sheet_data, case_num = self.loadExcel()
        for k, v in sheet_data:
            if k == sheet_name:
                try:
                    cell_exp = sheet_data[k].cell(case_order + 2, location_expect_result)
                    dict["expect"] = cell_exp.split('\n')
                except IndexError as e:
                    print("error", "Áî®‰æãÁºñÂè∑Ë∂ÖÂá∫Á¥¢ÂºïËåÉÂõ¥ÔºåËØ∑Ê£ÄÊü•ÁºñÂè∑ÊòØÂê¶Ê≠£Á°Æ")
        return dict

    def extract_sig_val(self, parseCSV: deque = None, parseDBC: dict = None) -> tuple:
        """
        ‰ªéÁî®‰æãÊñáÊ°£‰∏≠ÊèêÂèñÂá∫ÁöÑËæìÂÖ•ÂíåÈ¢ÑÊúüÁü©ÈòµÔºåÁªèÂ§ÑÁêÜÂêéÔºåÊåâÁÖßÁî®‰æãÁöÑÁª¥Â∫¶ÔºåÂ∞ÜËæìÂÖ•‰ø°Âè∑ÂèäÂÖ∂Êï∞ÂÄº„ÄÅËßÇÊµã‰ø°Âè∑ÂèäÂÖ∂È¢ÑÊúüÂÄº
        Â≠òÂÇ®Âà∞ÂàóË°®‰∏≠
        :param in_operation: ËæìÂÖ•Áü©ÈòµÔºåclass deque
        :param expect_operation: È¢ÑÊúüÁü©ÈòµÔºåclass deque
        :return: ÊâÄÊúâcaseÁöÑinput list, output list
        """
        in_operation = self._extractIn()
        out_operation = self._extractExp()
        pre_process_list = []  # ÂâçÁΩÆÊù°‰ª∂ Ê∂àÊÅØ-‰ø°Âè∑-ËÆæÂÆöÂÄº ÂàóË°®
        steps_list = []  # ÊµãËØïÊ≠•È™§ Ê∂àÊÅØ-‰ø°Âè∑-ËÆæÂÆöÂÄº ÂàóË°®
        input_list = []  # Êï¥‰∏™ËæìÂÖ• Ê∂àÊÅØ-‰ø°Âè∑-ËÆæÂÆöÂÄº ÂàóË°®
        expect_list = []  # È¢ÑÊúüÁªìÊûú Ê∂àÊÅØ-‰ø°Âè∑-È¢ÑÊúüÂÄº ÂàóË°®
        output_list = []  # Êï¥‰∏™È¢ÑÊúüÁªìÊûú Ê∂àÊÅØ-‰ø°Âè∑-È¢ÑÊúüÂÄº ÂàóË°®

        # ËæìÂÖ•‰∏∫DBCËß£ÊûêÂÜÖÂÆπ
        if parseDBC:
            for item_case in in_operation:
                if not item_case['pre_process']:
                    pre_process_list = []
                else:
                    for item_pre_process in item_case['pre_process']:
                        item_split_process = item_pre_process.split('=')
                        content_process = item_split_process[0]
                        wait_time = self.get_wait_time(content_process)
                        # Ëé∑ÂèñXCP‰ø°Âè∑
                        if self.is_calibration_variable(content=content_process):
                            pre_process_list.append(item_split_process)

                        #  Ëé∑ÂèñÁ≠âÂæÖÊó∂Èó¥
                        elif wait_time:
                            pre_process_list.append(wait_time)
                        #  Ëé∑ÂèñCAN‰ø°Âè∑ÂíåÂÆåÊï¥message‰ø°ÊÅØ
                        else:
                            item_split_process = self.get_can_signal(parsedbc=parseDBC, content=content_process, item_split_list=item_split_process)
                            pre_process_list.append(item_split_process)

                # ÊèêÂèñÊìç‰ΩúÊ≠•È™§ÁöÑ‰ø°Âè∑„ÄÇËã•‰∏∫Á©∫ÔºåÂàô‰∏çÂÅöÂ§ÑÁêÜ
                if not item_case['steps']:
                    steps_list = []
                else:
                    for item_steps in item_case['steps']:
                        item_split_steps = item_steps.split('=')
                        content_step = item_split_steps[0]
                        wait_time = self.get_wait_time(content_step)

                        # Ëé∑ÂèñXCP‰ø°Âè∑
                        if self.is_calibration_variable(content=content_step):
                            steps_list.append(item_split_steps)

                        #  Ëé∑ÂèñÁ≠âÂæÖÊó∂Èó¥
                        elif wait_time:
                            steps_list.append(wait_time)
                        #  Ëé∑ÂèñCAN‰ø°Âè∑ÂíåÂÆåÊï¥message‰ø°ÊÅØ
                        else:
                            item_split_steps = self.get_can_signal(parsedbc=parseDBC, content=content_step,
                                                                     item_split_list=item_split_steps)
                            steps_list.append(item_split_steps)

                # input_list  [[[case1.preprocess1], [case1.preprocess2], ... , [case1.steps1], ... ],
                # [[case2.proprecess],[case2.steps]],...]
                input_list.append(pre_process_list + steps_list)
                pre_process_list.clear()
                steps_list.clear()

            for item_case in out_operation:
                for item_pre_expect in item_case['expect']:
                    item_split_expect = item_pre_expect.split('=')
                    content_expect = item_split_expect[0]
                    for item_dbc_name, item_dbc_info in parseDBC.items():
                        for item_single_dbc_info in item_dbc_info:
                            if content_expect == item_single_dbc_info['signal_name']:
                                # item_split_process: [message_name, signal_name, exp_val, dbc_name]
                                item_split_expect.insert(0, item_single_dbc_info['message_name'])
                                item_split_expect.append(item_dbc_name)
                                break
                        if len(item_split_expect) == 4:
                            expect_list.append(item_split_expect)
                            break
                    if len(item_split_expect) == 2:
                        if self.is_calibration_variable(content_expect):
                            expect_list.append(item_split_expect)
                        else:
                            raise RuntimeError(f"Âä†ËΩΩÁöÑdbc‰∏≠Êó†Ê≠§‰ø°Âè∑: {content_expect}")
                output_list.append(copy.deepcopy(expect_list))
                expect_list.clear()

        # ËæìÂÖ•‰∏∫csvËß£ÊûêÂÜÖÂÆπ
        if parseCSV:
            for item_case in in_operation:
                for item_pre_process in item_case['pre_process']:
                    item_split_process = item_pre_process.split('=')
                    for item_csv_info in parseCSV:
                        if item_split_process[0] == item_csv_info['signal_name']:
                            # item_split_process: [message_name, signal_name, set_val]
                            item_split_process.insert(0, item_csv_info['message_name'])
                            break
                    if len(item_split_process) == 2:
                        raise RuntimeError(f"Âä†ËΩΩÁöÑdbc‰∏≠Êó†Ê≠§‰ø°Âè∑: {item_split_process[0]}")
                    pre_process_list.append(item_split_process)
                for item_steps in item_case['steps']:
                    item_split_steps = item_steps.split('=')
                    for item_csv_info in parseCSV:
                        if item_split_steps[0] == item_csv_info['signal_name']:
                            item_split_steps.insert(0, item_csv_info['message_name'])
                            break
                    if len(item_split_steps) == 2:
                        raise RuntimeError(f"Âä†ËΩΩÁöÑdbc‰∏≠Êó†Ê≠§‰ø°Âè∑: {item_split_steps[0]}")
                    steps_list.append(item_split_steps)
                input_list.append(pre_process_list + steps_list)
                pre_process_list.clear()
                steps_list.clear()

            for item_case in out_operation:
                for item_pre_expect in item_case['expect']:
                    item_split_expect = item_pre_expect.split('=')
                    for item_csv_info in parseCSV:
                        if item_split_expect[0] == item_csv_info['signal_name']:
                            # item_split_process: [message_name, signal_name, set_val]
                            item_split_expect.insert(0, item_csv_info['message_name'])
                            break
                    if len(item_split_expect) == 2:
                        raise RuntimeError(f"Âä†ËΩΩÁöÑdbc‰∏≠Êó†Ê≠§‰ø°Âè∑: {item_split_expect[0]}")
                    expect_list.append(item_split_expect)
                output_list.append(copy.deepcopy(expect_list))
                expect_list.clear()

        return input_list, output_list

    def extract_sig_val_single(self, parseDBC: dict = None, parseCSV: deque = None, sheet_name: str = "",
                               case_order: int = 0):
        """
        Ëé∑ÂèñÂçï‰æãÁöÑËæìÂÖ•ÔºåÈ¢ÑÊúüËæìÂá∫‰ø°Âè∑
        :param parseDBC:Ëß£ÊûêÂêéÁöÑdbcÊñá‰ª∂
        :param parseCSV: Ëß£ÊûêÂêéÁöÑcsvÊñá‰ª∂
        :param sheet_name: Âçï‰æãÊâÄÂú®sheet
        :param case_order: Âçï‰æãÂ∫èÂè∑ÔºåÁî®‰æã‰∏≠ÁöÑÁºñÂè∑ÔºåÈùûË°®Ê†ºË°åÊï∞
        :return:
        """
        in_operation = self._extractIn_single(sheet_name, case_order)  # dict
        out_operation = self._extractExp_single(sheet_name, case_order)  # dict

        input_pre_list = []
        input_steps_list = []
        output_exp_list = []
        # ÂàùÂßãÂåñËæìÂá∫ÂàóË°®
        input_list = []
        output_list = []

        if parseDBC:
            for item_input_pre in in_operation['pre_process']:
                item_input_pre.split('=')
                for item_dbc_name, item_dbc_info in parseDBC.items():
                    for item_single_dbc_info in item_dbc_info:
                        if item_input_pre[0] == item_single_dbc_info['signal_name']:
                            item_input_pre.insert(0, item_single_dbc_info['message_name'])
                            item_input_pre.append(item_dbc_name)
                            item_input_pre.append(item_single_dbc_info['cycle_time'])
                            break
                    if len(item_input_pre) == 5:
                        break
                if len(item_input_pre) == 2:
                    if item_input_pre[0].startswith("P_"):
                        pass
                    else:
                        raise RuntimeError(f"Âä†ËΩΩÁöÑdbc‰∏≠Êó†Ê≠§‰ø°Âè∑Ôºö {item_input_pre[0]}")
                input_pre_list.append(copy.deepcopy(item_input_pre))

            for item_input_steps in in_operation['steps']:
                item_input_steps.split('=')
                for item_dbc_name, item_dbc_info in parseDBC.items():
                    for item_single_dbc_info in item_dbc_info:
                        if item_input_steps[0] == item_single_dbc_info['signal_name']:
                            item_input_steps.insert(0, item_single_dbc_info['message_name'])
                            item_input_steps.append(item_dbc_name)
                            item_input_steps.append(item_single_dbc_info["cycle_time"])
                            break
                    if len(item_input_steps) == 5:
                        break
                if len(item_input_steps) == 2:
                    if item_input_steps[0].startswith("P_"):
                        pass
                    else:
                        raise RuntimeError(f"Âä†ËΩΩÁöÑdbc‰∏≠Êó†Ê≠§‰ø°Âè∑Ôºö {item_input_steps[0]}")
                input_steps_list.append(copy.deepcopy(item_input_steps))

            input_list.append(input_pre_list + input_steps_list)

            for item_expect in out_operation['expect']:
                item_expect.split('=')
                for item_dbc_name, item_dbc_info in parseDBC.items():
                    for item_single_dbc_info in item_dbc_info:
                        if item_expect[0] == item_single_dbc_info['signal_name']:
                            item_expect.insert(0, item_single_dbc_info['message_name'])
                            item_expect.append(item_dbc_name)
                            break
                    if len(item_expect) == 4:
                        break

                if len(item_expect) == 2:
                    if item_expect[0].startswith("In_"):
                        pass
                    else:
                        raise RuntimeError(f"Âä†ËΩΩÁöÑdbc‰∏≠Êó†Ê≠§‰ø°Âè∑Ôºö {item_expect[0]}")
                output_exp_list.append(copy.deepcopy(item_expect))
                output_list.append(output_exp_list)

        if parseCSV:
            for item_input_pre in in_operation['pre_process']:
                item_input_pre.split('=')
                for item_dbc_info in parseCSV:
                    if item_input_pre[0] == item_dbc_info['signal_name']:
                        item_input_pre.insert(0, item_dbc_info['message_name'])
                        break
                if len(item_input_pre) == 2:
                    raise RuntimeError(f"Âä†ËΩΩÁöÑdbc‰∏≠Êó†Ê≠§‰ø°Âè∑Ôºö {item_input_pre[0]}")
                input_pre_list.append(copy.deepcopy(item_input_pre))

            for item_input_steps in in_operation['steps']:
                item_input_steps.split('=')
                for item_dbc_info in parseCSV:
                    if item_input_steps[0] == item_dbc_info['signal_name']:
                        item_input_steps.insert(0, item_dbc_info['message_name'])
                        break
                if len(item_input_steps) == 2:
                    raise RuntimeError(f"Âä†ËΩΩÁöÑdbc‰∏≠Êó†Ê≠§‰ø°Âè∑Ôºö {item_input_steps[0]}")
                input_steps_list.append(copy.deepcopy(item_input_steps))

            input_list.append(input_pre_list + input_steps_list)

            for item_expect in out_operation['expect']:
                item_expect.split('=')
                for item_dbc_info in parseCSV:
                    if item_expect[0] == item_dbc_info['signal_name']:
                        item_expect.insert(0, item_dbc_info['message_name'])
                        break
                if len(item_expect) == 2:
                    raise RuntimeError(f"Âä†ËΩΩÁöÑdbc‰∏≠Êó†Ê≠§‰ø°Âè∑Ôºö {item_expect[0]}")
                output_exp_list.append(copy.deepcopy(item_expect))
                output_list.append(output_exp_list)

        # input_list: [msg_name, sig_name, set_val, dbc_name, cycle_time]
        # output_list: [msg_name, sig_name, dbc_name]
        return input_list, output_list

    def get_wait_time(self, content)->list:
        if content.startswith("wait"):
            string_time = content.split(" ")[-1]
            return list(string_time.split("s")[0]) # ËøîÂõûÁ≠âÂæÖÊó∂Èïø

    def is_calibration_variable(self, content)->bool:
        if content.startswith("P_") or \
            content.startswith("Out_") or \
            content.startswith("env_") or content.startswith("In_"):
            # print(str(content), " is a calibration\XCP object!")
            return True

    def get_can_signal(self, parsedbc: dict, content, item_split_list)->list:
        for item_dbc_name, item_dbc_info in parsedbc.items():
            for item_single_dbc_info in item_dbc_info:
                if content == item_single_dbc_info['signal_name']:
                    item_split_list.insert(0, item_single_dbc_info['message_name'])
                    item_split_list.append(item_dbc_name)
                    item_split_list.append(item_single_dbc_info["cycle_time"])
                    break
                else:
                    pass
            if len(item_split_list) == 5:
                break
        if len(item_split_list) == 5:
            return item_split_list
        else:
            raise RuntimeError(f"Âä†ËΩΩÁöÑdbc‰∏≠Êó†Ê≠§‰ø°Âè∑: {content}")

# DBC Êñá‰ª∂Ê†ºÂºèÁõ∏ÂÖ≥ÁöÑÂèÇÊï∞
length_of_BO1 = 6  # BO_ÂºÄÂ§¥ÁöÑË°å‰∏∫messageÊèèËø∞Ë°åÔºåÂàÜÂâ≤ÂêéÂèØ‰ª•ÂΩ¢ÊàêÈïøÂ∫¶‰∏∫5ÁöÑÊï∞ÁªÑÔºåBO_ 292 SP1_Info1_10ms: 32 FSD1
length_of_BO2 = 5
str_of_BO = 'BO_'  # Ê∂àÊÅØË°åÂºÄÂ§¥
str_of_SG = 'SG_'  # ‰ø°Âè∑Ë°åÂºÄÂ§¥
str_of_BA = 'BA_'  # Ê∂àÊÅØÂ±ûÊÄßË°åÂºÄÂ§¥
location_of_bo_id = 1  # Ê∂àÊÅØÂú∞ÂùÄÔºàidÔºâÊâÄÂú®‰ΩçÁΩÆ
location_of_bo_message_name = 2  # Ê∂àÊÅØÂêçÊâÄÂú®‰ΩçÁΩÆ
location_of_bo_dlc = 3  # Ê∂àÊÅØÈïøÂ∫¶ÊâÄÂú®‰ΩçÁΩÆ
location_of_bo_transmitter = 4  # Ê∂àÊÅØÂèëÈÄÅËäÇÁÇπÊâÄÂú®‰ΩçÁΩÆ

# ‰ø°Âè∑Ë°å‰∏æ‰æã  SG_ TimeToRbump : 77|10@0+ (0.1,0) [0|102.3] ""  Vector_XXX
location_of_sg_type = 0
location_of_sg_name = 1
location_of_sg_factor = 4
location_of_sg_max_min = 5
location_of_sg_receiver = 7


# DBC load class
class DBCload(object):
    """
    Ëß£ÊûêÂ§ÑÁêÜÂçï‰∏™DBCÊñá‰ª∂ .dbc
    """

    def __init__(self, dbc_name_in):
        self.dbc_fd = open(dbc_name_in, 'r')
        if self.dbc_fd.readable():
            self.num_of_bo = 0  # È¢ÑÁïô
            self.num_of_sg = 0  # È¢ÑÁïô
            self.dbc_list = []
            self.dbc_name = dbc_name_in
            self.dbc_cycle_time = {}
            self.dbc_send_type = {}
            # self.dbc_start_delay_time = {}
        else:
            print('DBC file load failed!')

    def parseDBC(self):
        """
        ‰ªéDBC‰∏≠Ëé∑ÂèñÊ∂àÊÅØÂíå‰ø°Âè∑ÁöÑÂ±ûÊÄß
        Ê∂àÊÅØÔºö ÂêçÁß∞  ID  ÂèëÈÄÅÊñπÂºè   ÂèëÈÄÅÂë®Êúü   ÈáçÂ§çÂèëÈÄÅÊ¨°Êï∞  Âª∂ËøüÂèëÈÄÅÊó∂Èó¥
        ‰ø°Âè∑Ôºö ÂêçÁß∞  factor  offset  ÊúÄÂ§ßÂÄº  ÊúÄÂ∞èÂÄº
        ÂèëÈÄÅÂë®ÊúüÔºö  Âë®ÊúüÂèëÈÄÅ       cyclic                           0
                  ‰∫ã‰ª∂Ëß¶Âèë       spontaneous                      1
                  ÊøÄÊ¥ªÂêéÂæ™ÁéØ     cyclicIfActive                   2
                  Ëß¶ÂèëÂêéÂª∂Êó∂     spontaneousWithDelay             3
                  Ëß¶ÂèëÂêéÂæ™ÁéØ     cyclicAndSpontaneous             4
                  Ëß¶ÂèëÂêéÂª∂Êó∂Âæ™ÁéØ  cyclicAndSpontaneousWithDelay    5
                  ÊøÄÊ¥ª          ifActive                         6
        :return:
        """
        # ËØªÂèñdbcÊñá‰ª∂
        line_list = self.dbc_fd.readlines()  # ÈÄêË°åËØªÂèñdbcÔºåÊØèË°åÂÜÖÂÆπ‰Ωú‰∏∫ÂÖÉÁ¥†‰øùÂ≠òËá≥ÂàóË°®‰∏≠
        # print(line_list)
        dbc_name = self.dbc_name.split('/')[-1]
        dbc_txt_name = dbc_name.strip('.dbc')
        '''
        # ‰øùÂ≠òËá≥txtÊñá‰ª∂‰∏≠
        with open(r'../DBC' + time.strftime('%Y-%m-%d-%H-%M-%S') + dbc_txt_name + '.txt', 'w') as f:
            for item in line_list:
                f.write(item)
        '''
        # ÊèêÂèñÊ∂àÊÅØÂÜÖÂÆπ
        for txt_line in line_list:
            txt_line_list = txt_line.split()
            # Êü•ÊâæÊ∂àÊÅØÂ±ûÊÄßÊèèËø∞Ë°å
            if len(txt_line_list) > 2 and txt_line_list[0] == str_of_BA:
                # Â∞Ü Ê∂àÊÅØID Âíå ÂèëÈÄÅÂë®Êúü ‰øùÂ≠òËá≥dbc_cycle_timeÂ≠óÂÖ∏‰∏≠
                if txt_line_list[1] == '"GenMsgCycleTime"':
                    self.dbc_cycle_time[txt_line_list[3]] = int(float(re.sub(';', '', txt_line_list[4])))
                # Â∞Ü Ê∂àÊÅØID Âíå ÂèëÈÄÅÊñπÂºè ‰øùÂ≠òËá≥dbc_send_typeÂ≠óÂÖ∏‰∏≠
                if txt_line_list[1] == '"GenMsgSendType"':
                    self.dbc_send_type[txt_line_list[3]] = int(re.sub(';', '', txt_line_list[4]))

        bo_list = []
        i = 0
        for i in range(len(line_list) - 1):
            txt_line_list = line_list[i].split()
            # Êü•ÊâæmessageÊèèËø∞Ë°å
            if (len(txt_line_list) == length_of_BO1 or len(txt_line_list) == length_of_BO2) and txt_line_list[
                0] == str_of_BO:
                # BO_ 661 FSD1_Info_FB_20ms : 32 Vector_XXX or BO_ 661 FSD1_Info_FB_20ms: 32 Vector_XXX
                # ËÆ∞ÂΩïÊ∂àÊÅØÂêçÁß∞„ÄÅID„ÄÅÂèëÈÄÅÂë®Êúü„ÄÅÂèëÈÄÅÊñπÂºè
                bo_dict = {'msg_name': re.sub(':', '', txt_line_list[location_of_bo_message_name]),
                           'msg_ID_DEC': int(txt_line_list[location_of_bo_id])}
                if str(bo_dict['msg_ID_DEC']) in self.dbc_cycle_time:
                    bo_dict['msg_cycle_time'] = self.dbc_cycle_time[str(bo_dict['msg_ID_DEC'])]
                else:
                    bo_dict['msg_cycle_time'] = 100000000
                if str(bo_dict['msg_ID_DEC']) in self.dbc_send_type:
                    bo_dict['msg_send_type'] = self.dbc_send_type[str(bo_dict['msg_ID_DEC'])]

                if line_list[i + 1] != "\n":  # ‰∏ÄÊù°Ê∂àÊÅØÁöÑ‰ø°Âè∑Á∞á‰ª•Á©∫Ë°åÂàÜÊÆµÔºåÊïÖ‰ª•Ê≠§‰Ωú‰∏∫Ê∂àÊÅØÁöÑÂàÜÂâ≤Á¨¶
                    i += 1
                    while len(line_list[i]) > 2 and line_list[i].split()[0] == str_of_SG:
                        sg_list = line_list[i].split()
                        sg_dict = {'message_name': bo_dict['msg_name'], 'signal_name': sg_list[location_of_sg_name],
                                   'msg_ID_DEC': bo_dict['msg_ID_DEC'], 'cycle_time': bo_dict['msg_cycle_time']}

                        if sg_list[2] != ':':
                            offset = 1
                        else:
                            offset = 0
                        end_of_factor = sg_list[location_of_sg_factor + offset].find(',')
                        end_of_offset = sg_list[location_of_sg_factor + offset].find(')')
                        sg_dict['factor'] = float(sg_list[location_of_sg_factor + offset][1:end_of_factor])
                        sg_dict['offset'] = float(
                            sg_list[location_of_sg_factor + offset][end_of_factor + 1:end_of_offset])
                        end_of_min = sg_list[location_of_sg_max_min + offset].find('|')
                        end_of_max = sg_list[location_of_sg_max_min + offset].find(']')
                        sg_dict['minimum'] = float(sg_list[location_of_sg_max_min + offset][1:end_of_min])
                        sg_dict['maximum'] = float(sg_list[location_of_sg_max_min + offset][end_of_min + 1:end_of_max])

                        bo_list.append(sg_dict)
                        i += 1

        dbc_text_name = dbc_txt_name.split('_')[-1]
        # print({dbc_text_name: bo_list})
        # ËøîÂõûÂ≠óÂÖ∏ÔºåÂ¶Ç{"CHCAN1": [{"message_name": a, "signal_name": b,...},...]}
        # ËøîÂõûdbcÂêçÁß∞ÁöÑÂéüÂõ†ÊòØË¶ÅÈÖçÂêàcanoeÈÖçÁΩÆÁöÑÈÄöÈÅìÔºåÂú®Êî∂Âèë‰ø°Âè∑Êó∂ÈÄâÊã©ÂêàÈÄÇÁöÑÈÄöÈÅì
        return {dbc_text_name: bo_list}


# debug
# dbc = DBCload(r'D:\liyi10\project\VMM\X01-610VMM(1)\X01_CAN_Matrix_V6.0.0_20220510_FSD2_CHCAN2.dbc')
# dbc.parseDBC()

# csvÊØèË°å‰∏≠‰∏çÂêåÊù°ÁõÆÁöÑ‰ΩçÁΩÆ‰ø°ÊÅØ
location_sg = 0
location_ms = 1
location_Trans = 4
location_msId = 16
location_sig_cyc_time = 17
location_sig_timeout = 23


# csv load class
class csvload(object):
    def __init__(self, csv_name_in):
        self.csv_in = open(csv_name_in, 'r')
        if self.csv_in.readable():
            self.num_sg = 0
            self.text_lines = []
            self.table_sg_ms_msId_trans_sigCycTime_sigTimeOut = deque()
        else:
            raise FileExistsError('Êñá‰ª∂Âä†ËΩΩÂ§±Ë¥•ÔºÅ')

    def parse_csv(self) -> deque:
        self.text_lines = self.csv_in.readlines()
        self.text_lines.pop(0)
        # print(self.text_lines)
        dict = {}
        de1 = deque()
        count = 0
        for item in self.text_lines:
            item.strip('\n')
            item = item.split(';')
            # print(item)
            dict['signal_name'] = item[location_sg]
            dict['message_name'] = item[location_ms]
            dict['message_Id'] = item[location_msId]
            dict['transmitter'] = item[location_Trans]
            dict['sigCycleTime'] = item[location_sig_cyc_time]
            # dict['sigTimeOut'] = item[location_sig_timeout]
            dict_new = deepcopy(dict)
            self.table_sg_ms_msId_trans_sigCycTime_sigTimeOut.append(dict_new)
        # print(self.table_sg_ms_msId_trans_sigCycTime_sigTimeOut)
        return self.table_sg_ms_msId_trans_sigCycTime_sigTimeOut

# if __name__ == "__main__":
#     filepath = r"D:/liyi10/project/VMM/X01-610VMM(1)/X01_CAN_Matrix_V6.0.0_20220510_FSD1_CHCAN1.dbc"
#     d = DBCload(filepath)
#     print(d.parseDBC())
# debug
# if __name__ == "__main__":
#     filepath = r"D:\liyi10\Desktop\testToolCase2.xlsx"
#     data = DataProcess(filepath)
#     in_operation = data.extractIn()
#     out_operation = data.extractExp()
# # # #     # data.loadExcel()
#     csv_name = r'D:\liyi10\Desktop\ObjectList_show.csv'
#     csv = csvload(csv_name)
#     parseCSV = csv.parse_csv()
#     print(data.extract_sig_val(parseCSV))
#                      üëá
# ([[['ESP_Alarm_20ms_Rt_FD', 'ABSCtrlA', '1'], ['XCU_Info_10ms_FD', 'AccelPdlPos', '2'],
#    ['IBooster_Info2_10ms_FD', 'ActOutputRod', '3']],
#   [['XCU_HU_Cmd3_ETH1_100mixed', 'AirSusLoadMdSwReq', '1'], ['ASU_DTC', 'ASU_DTC1_Num', '2'],
#    ['ASU_DTC', 'ASU_DTC4_State', '3']],
#   [['ESP_Alarm_20ms_Rt_FD', 'ABSCtrlA', '1'], ['XCU_Info_10ms_FD', 'AccelPdlPos', '2'],
#    {'IBooster_Info2_10ms_FD', 'ActOutputRod', '3'}],
#   [['XCU_HU_Cmd3_ETH1_100mixed', 'AirSusLoadMdSwReq', '1'], ['ASU_DTC', 'ASU_DTC1_Num', '2'],
#    ['ASU_DTC', 'ASU_DTC4_State', '3']]], [
#      [['ESP_Alarm_20ms_Rt_FD', 'ABSCtrlA', '1'], ['XCU_Info_10ms_FD', 'AccelPdlPos', '2'],
#       ['IBooster_Info2_10ms_FD', 'ActOutputRod', '3']],
#      [['XCU_HU_Cmd3_ETH1_100mixed', 'AirSusLoadMdSwReq', '1'], ['ASU_DTC', 'ASU_DTC1_Num', '2'],
#       ['ASU_DTC', 'ASU_DTC4_State', '3']],
#      [['ESP_Alarm_20ms_Rt_FD', 'ABSCtrlA', '1'], ['XCU_Info_10ms_FD', 'AccelPdlPos', '2'],
#       ['IBooster_Info2_10ms_FD', 'ActOutputRod', '3']],
#      [['XCU_HU_Cmd3_ETH1_100mixed', 'AirSusLoadMdSwReq', '1'], ['ASU_DTC', 'ASU_DTC1_Num', '2'],
#       ['ASU_DTC', 'ASU_DTC4_State', '3']]])
